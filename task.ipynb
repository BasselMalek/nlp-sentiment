{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Sentiment Analysis Notebook\n",
                "\n",
                "Sentiment analysis notebook with a simple RNN by Basel."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Includes"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "\n",
                "import nltk\n",
                "from nltk.corpus import stopwords\n",
                "from nltk.tokenize import word_tokenize\n",
                "from nltk.stem import PorterStemmer\n",
                "import re as reg\n",
                "import string\n",
                "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
                "\n",
                "\n",
                "nltk.download('punkt')\n",
                "nltk.download('punkt_tab')\n",
                "nltk.download('stopwords')\n",
                "nltk.download('wordnet')\n",
                "\n",
                "from sklearn.feature_extraction.text import CountVectorizer\n",
                "\n",
                "from sklearn.model_selection import train_test_split, cross_val_score\n",
                "\n",
                "\n",
                "# Eval\n",
                "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
                "from sklearn.metrics import confusion_matrix, classification_report\n",
                "\n",
                "\n",
                "\n",
                "pd.set_option('display.max_colwidth', 100)\n",
                "plt.style.use('ggplot')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Dataset info"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "splits = {'train': 'train_df.csv', 'validation': 'val_df.csv', 'test': 'test_df.csv'}\n",
                "df = pd.read_csv(\"hf://datasets/Sp1786/multiclass-sentiment-analysis-dataset/\" + splits[\"train\"])\n",
                "print(f\"Dataset shape: {df.shape}\")\n",
                "print(\"\\nFirst few rows:\")\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"nulls:\")\n",
                "df.isnull().sum()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"has links?\")\n",
                "df[df['text'].str.contains('https?')].head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"all english letters?\")\n",
                "df[df['text'].str.contains('[^\\x00-\\x7F]')].head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Cleaning and stemming"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def cleaner(text):\n",
                "    text = text.lower()\n",
                "    text = reg.sub(r'http\\S+|www\\S+|https\\S+', '', text)\n",
                "    text = reg.sub(r'@\\w+', '', text)\n",
                "    text = reg.sub(r'[^a-zA-Z\\s]', '', text)    \n",
                "    text = reg.sub(r'\\s+', ' ', text).strip()\n",
                "    return text\n",
                "df['cleaned_text'] = df['text'].apply(cleaner)\n",
                "print(\"any stragglers?\")\n",
                "df[df['cleaned_text'].str.contains('[^\\x00-\\x7F]')].head()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def preprocesser(text):\n",
                "    # tokenize\n",
                "    tokens = word_tokenize(text)\n",
                "    stop_words = set(stopwords.words('english'))\n",
                "    tokens = [token for token in tokens if token not in stop_words]\n",
                "    \n",
                "    # stem\n",
                "    stemmer = PorterStemmer()\n",
                "    stemmed_tokens = [stemmer.stem(token) for token in tokens]\n",
                "    \n",
                "    processed_text = ' '.join(stemmed_tokens)\n",
                "    \n",
                "    return processed_text\n",
                "\n",
                "df['processed_text'] = df['cleaned_text'].apply(preprocesser)\n",
                "df['processed_text'].head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. CBOWing and stuff"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Using Bag of Words (CountVectorizer)\n",
                "count_vectorizer = CountVectorizer(max_features=5000)\n",
                "X_count = count_vectorizer.fit_transform(df['processed_text'])\n",
                "\n",
                "\n",
                "print(\"cbow shape:\", X_count.shape)\n",
                "\n",
                "X = X_count\n",
                "y = df['label']"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Divorcing the dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "X_train, X_test, y_train, y_test = train_test_split(\n",
                "    X, y, test_size=0.2, random_state=42\n",
                ")\n",
                "print(\"Training set shape:\", X_train.shape)\n",
                "print(\"Testing set shape:\", X_test.shape)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. IT'S ALIVE, sike not yet gotta pad\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "ename": "NameError",
                    "evalue": "name 'X_train' is not defined",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
                        "Cell \u001b[1;32mIn[4], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Import necessary libraries\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msequence\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pad_sequences\n\u001b[1;32m----> 5\u001b[0m padded_sequences \u001b[38;5;241m=\u001b[39m pad_sequences(\u001b[43mX_train\u001b[49m, \n\u001b[0;32m      6\u001b[0m                                 maxlen\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m,\n\u001b[0;32m      7\u001b[0m                                 padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      8\u001b[0m                                 truncating\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of padded sequences:\u001b[39m\u001b[38;5;124m\"\u001b[39m, padded_sequences\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExample of padded sequence:\u001b[39m\u001b[38;5;124m\"\u001b[39m, padded_sequences[\u001b[38;5;241m0\u001b[39m])\n",
                        "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
                    ]
                }
            ],
            "source": [
                "\n",
                "\n",
                "padded_sequences = pad_sequences(X_train, \n",
                "                                maxlen=50,\n",
                "                                padding='post',\n",
                "                                truncating='post')\n",
                "\n",
                "print(\"Shape of padded sequences:\", padded_sequences.shape)\n",
                "print(\"Example of padded sequence:\", padded_sequences[0])\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.7"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
